<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0041)http://mmlab.ie.cuhk.edu.hk/projects/M&M/ -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Mix-and-Match Tuning for Self-Supervised Semantic Segmentation</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="The training of many existing end-to-end steering angle prediction models heavily relies on steering angles as the supervisory signal. Without learning from much richer contexts, these methods are susceptible to the presence of sharp road curves, challenging traffic conditions, strong shadows, and severe lighting changes. In this paper, we considerably improve the accuracy and robustness of predictions through heterogeneous auxiliary networks feature mimicking, a new and effective training method that provides us with much richer contextual signals apart from steering direction. Specifically, we train our steering angle predictive model by distilling multi-layer knowledge from multiple heterogeneous auxiliary networks that perform related but different tasks, e.g., image segmentation or optical flow estimation. As opposed to multi-task learning, our method does not require expensive annotations of related tasks on the target set. This is made possible by applying contemporary off-the-shelf networks on the target set and mimicking their features in different layers after transformation. The auxiliary networks are discarded after training without affecting the runtime efficiency of our model. Our approach achieves a new state-of-the-art on Udacity and Comma.ai, outperforming the previous best by a large margin of 12.8% and 52.1%, respectively. Encouraging results are also shown on Berkeley Deep Drive (BDD) dataset.&gt;
&lt;meta name=" keywords"="">
<link rel="author" href="https://liuziwei7.github.io/">

<!-- Fonts and stuff -->
<link href="./Mix-and-Match Tuning for Self-Supervised Semantic Segmentation_files/css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="./Mix-and-Match Tuning for Self-Supervised Semantic Segmentation_files/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./Mix-and-Match Tuning for Self-Supervised Semantic Segmentation_files/iconize.css">
<script type="text/javascript" async="" src="./Mix-and-Match Tuning for Self-Supervised Semantic Segmentation_files/ga.js"></script><script async="" src="./Mix-and-Match Tuning for Self-Supervised Semantic Segmentation_files/prettify.js"></script>

<script type="text/javascript">
            
            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-22940424-1']);
            _gaq.push(['_trackPageview']);
            
            (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
            })();
            
</script>

</head>

<body>
  <div id="content">
    <div id="content-inner">
      
      <div class="section head">
	<h1>Mix-and-Match Tuning for</h1>
	<h1>Self-Supervised Semantic Segmentation</h1>

	<div class="authors">
	  <a href="https://xiaohangzhan.github.io/">Xiaohang Zhan</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://liuziwei7.github.io/">Ziwei Liu</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="http://personal.ie.cuhk.edu.hk/~pluo/">Ping Luo</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="http://www.ie.cuhk.edu.hk/people/xotang.shtml">Xiaoou Tang</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="http://personal.ie.cuhk.edu.hk/~ccloy/">Chen Change Loy</a>
	</div>

	<div class="affiliations">
	  <a href="http://mmlab.ie.cuhk.edu.hk/">Multimedia Laboratory, </a>
	  <a href="http://www.cuhk.edu.hk/english/index.html">The Chinese University of Hong Kong</a>
	</div>

	<div class="venue">AAAI Conference on Artificial Intelligence (<a href="https://aaai.org/Conferences/AAAI-18/" target="_blank">AAAI</a>) 2018</div>
      </div>

      
      <center><img src="./Mix-and-Match Tuning for Self-Supervised Semantic Segmentation_files/intro.png" border="0" width="90%"></center>

<div class="section abstract">
	<h2>Abstract</h2>
	<br>
	<p>
The training of many existing end-to-end steering angle prediction models heavily relies on steering angles as the supervisory signal. Without learning from much richer contexts, these methods are susceptible to the presence of sharp road curves, challenging traffic conditions, strong shadows, and severe lighting changes. In this paper, we considerably improve the accuracy and robustness of predictions through heterogeneous auxiliary networks feature mimicking, a new and effective training method that provides us with much richer contextual signals apart from steering direction. Specifically, we train our steering angle predictive model by distilling multi-layer knowledge from multiple heterogeneous auxiliary networks that perform related but different tasks, e.g., image segmentation or optical flow estimation. As opposed to multi-task learning, our method does not require expensive annotations of related tasks on the target set. This is made possible by applying contemporary off-the-shelf networks on the target set and mimicking their features in different layers after transformation. The auxiliary networks are discarded after training without affecting the runtime efficiency of our model. Our approach achieves a new state-of-the-art on Udacity and Comma.ai, outperforming the previous best by a large margin of 12.8% and 52.1%, respectively. Encouraging results are also shown on Berkeley Deep Drive (BDD) dataset.
	</p>
      </div>
      
<div class="section materials">
	<h2>Materials</h2>
	<center>
	  <ul>
           
          <li class="grid">
	      <div class="griditem">
		<a href="https://arxiv.org/abs/1712.00661" target="_blank" class="imageLink"><img src="./Mix-and-Match Tuning for Self-Supervised Semantic Segmentation_files/paper.png"></a><br>
		  <a href="https://arxiv.org/abs/1712.00661" target="_blank">Paper</a>
		</div>
	      </li>
	  
	    </ul>
	    </center>
	    </div>
	    
<br>

<div class="section code">
	<h2>Code and Models</h2>
	<center>
	  <ul>
           
          <li class="grid">
	      <div class="griditem">
		<a href="https://github.com/XiaohangZhan/mix-and-match/" target="_blank" class="imageLink"><img src="./Mix-and-Match Tuning for Self-Supervised Semantic Segmentation_files/code.png"></a><br>
		  <a href="https://github.com/XiaohangZhan/mix-and-match/" target="_blank">Code and Models</a>
		</div>
	      </li>

	    </ul>
	    </center>
	    </div>
	    
<br>

<div class="section citation">
	<h2>Citation</h2>
	<div class="section bibtex">
	  <pre>@inproceedings{zhan2018m&amp;m,
 author = {Xiaohang Zhan, Ziwei Liu, Ping Luo, Xiaoou Tang, and Chen Change Loy},
 title = {Mix-and-Match Tuning for Self-Supervised Semantic Segmentation},
 booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
 month = {February},
 year = {2018} 
}</pre>
	  </div>
      </div>

</div></div></body></html>
