<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0041)http://mmlab.ie.cuhk.edu.hk/projects/M&M/ -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Learning to Steer by Mimicking Features from Heterogeneous Auxiliary Networks</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="
The training of many existing end-to-end steering angle prediction models heavily relies on steering angles as the supervisory signal. Without learning from much richer contexts, these methods are susceptible to the presence of sharp road curves, challenging traffic conditions, strong shadows, and severe lighting changes. In this paper, we considerably improve the accuracy and robustness of predictions through heterogeneous auxiliary networks feature mimicking, a new and effective training method that provides us with much richer contextual signals apart from steering direction. Specifically, we train our steering angle predictive model by distilling multi-layer knowledge from multiple heterogeneous auxiliary networks that perform related but different tasks, e.g., image segmentation or optical flow estimation. As opposed to multi-task learning, our method does not require expensive annotations of related tasks on the target set. This is made possible by applying contemporary off-the-shelf networks on the target set and mimicking their features in different layers after transformation. The auxiliary networks are discarded after training without affecting the runtime efficiency of our model. Our approach achieves a new state-of-the-art on Udacity and Comma.ai, outperforming the previous best by a large margin of 12.8% and 52.1%, respectively. Encouraging results are also shown on Berkeley Deep Drive (BDD) dataset.&gt;
&lt;meta name=" keywords"="">
<link rel="author" href="https://liuziwei7.github.io/">

<!-- Fonts and stuff -->
<link href="./css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="./project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./iconize.css">
</script><script async="" src="./prettify.js"></script>

<script type="text/javascript">
            
            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-22940424-1']);
            _gaq.push(['_trackPageview']);
            
            (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
            })();
            
</script>

</head>

<body>
  <div id="content">
    <div id="content-inner">
      
      <div class="section head">
	<h1>Learning to Steer by</h1>
	<h1>Mimicking Features from Heterogeneous Auxiliary Networks</h1>

	<div class="authors">
	  <a href="https://cardwing.github.io/">Yuenan Hou</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="http://visal.cs.cityu.edu.hk/people/zheng-ma/">Zheng Ma</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://scholar.google.com/citations?user=4m061tYAAAAJ&hl=en">Chunxiao Liu</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://scholar.google.com/citations?user=559LF80AAAAJ&hl=en">Chen Change Loy</a>
	</div>

	<div class="affiliations">
	  <a href="http://mmlab.ie.cuhk.edu.hk/">Multimedia Laboratory, </a>
	  <a href="http://www.cuhk.edu.hk/english/index.html">The Chinese University of Hong Kong</a>
	</div>

	<div class="venue">AAAI Conference on Artificial Intelligence (<a href="https://aaai.org/Conferences/AAAI-19/" target="_blank">AAAI</a>) 2019</div>
      </div>

      
      <center><img src="./inro.png" border="0" width="90%"></center>

<div class="section abstract">
	<h2>Abstract</h2>
	<br>
	<p>
The training of many existing end-to-end steering angle prediction models heavily relies on steering angles as the supervisory signal. Without learning from much richer contexts, these methods are susceptible to the presence of sharp road curves, challenging traffic conditions, strong shadows, and severe lighting changes. In this paper, we considerably improve the accuracy and robustness of predictions through heterogeneous auxiliary networks feature mimicking, a new and effective training method that provides us with much richer contextual signals apart from steering direction. Specifically, we train our steering angle predictive model by distilling multi-layer knowledge from multiple heterogeneous auxiliary networks that perform related but different tasks, e.g., image segmentation or optical flow estimation. As opposed to multi-task learning, our method does not require expensive annotations of related tasks on the target set. This is made possible by applying contemporary off-the-shelf networks on the target set and mimicking their features in different layers after transformation. The auxiliary networks are discarded after training without affecting the runtime efficiency of our model. Our approach achieves a new state-of-the-art on Udacity and Comma.ai, outperforming the previous best by a large margin of 12.8% and 52.1%, respectively. Encouraging results are also shown on Berkeley Deep Drive (BDD) dataset.
	</p>
      </div>
      
<div class="section materials">
	<h2>Materials</h2>
	<center>
	  <ul>
           
          <li class="grid">
	      <div class="griditem">
		<a href="https://arxiv.org/abs/1712.00661" target="_blank" class="imageLink"><img src="./paper.png"></a><br>
		  <a href="https://arxiv.org/abs/1712.00661" target="_blank">Paper</a>
		</div>
	      </li>
	  
	    </ul>
	    </center>
	    </div>
	    
<br>

<div class="section code">
	<h2>Code and Models</h2>
	<center>
	  <ul>
           
          <li class="grid">
	      <div class="griditem">
		<a href="https://github.com/cardwing/Codes-for-Steering-Control" target="_blank" class="imageLink"><img src="./code.png"></a><br>
		  <a href="https://github.com/cardwing/Codes-for-Steering-Control" target="_blank">Code and Models</a>
		</div>
	      </li>

	    </ul>
	    </center>
	    </div>
	    
<br>

<div class="section citation">
	<h2>Citation</h2>
	<div class="section bibtex">
	  <pre>@inproceedings{xxx,
 author = {Yuenan Hou, Zheng Ma, Chunxiao Liu, and Chen Change Loy},
 title = {Learning to Steer by Mimicking Features from Heterogeneous Auxiliary Networks},
 booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
 month = {February},
 year = {2019} 
}</pre>
	  </div>
      </div>

</div></div></body></html>

