
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <style type="text/css">
    #sectiontohide {
      padding: 20px;
      background: #f0f0f0;
      width: 400px;
    }
  </style>
  <script type="text/javascript">
    function toggle_div_fun(id) {

      var divelement = document.getElementById(id);

      if (divelement.style.display == 'none')
        divelement.style.display = 'block';
      else
        divelement.style.display = 'none';
    }
  </script>
  <title>HOU Yuenan (侯跃南)</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>HOU Yuenan (侯跃南)</name>
              </p>
              <p>
                Yuenan Hou obtained the Ph.D. degree from the Chinese University of Hong Kong (<a href="http://mmlab.ie.cuhk.edu.hk/index.html">Multimedia Lab</a>) in August 2021, under the supervision of Prof.
                <a href="https://scholar.google.com/citations?user=559LF80AAAAJ&hl=en">Chen Change Loy</a> and Prof.
                <a href="https://scholar.google.com/citations?user=qpBtpGsAAAAJ&hl=en">Xiaoou Tang</a>. He received his B.E degree from Nanjing University in July 2017, supervised by Prof. <a href="https://scholar.google.com.hk/citations?user=5kXEo74AAAAJ&hl=en">Chunlin Chen</a> and Prof. <a href="https://www.researchgate.net/profile/Xianzhong_Zhou">Xianzhong Zhou</a>.
                His research interest includes <b>3D perception</b>, <b>model compression</b>, <b>multi-modal learning</b> and <b> semantic scene understanding</b>.
              </p>
              <p align=center>
                <a href="mailto:Yuenan_Hou@163.com"> Email </a> /
                <!-- <a href="https://www.linkedin.com/in/yuenan-hou-859589136/"> LinkedIn </a> /
                <a href="https://scholar.google.com.hk/citations?user=o9mX9sUAAAAJ&hl=en"> Google Scholar </a> /
                <a href="https://github.com/cardwing"> Github </a>
              </p>
            </td>
            <td width="15%">
              <right><img src="Me.jpg" width="200" height="150"></right>
            </td>
          </tr>
        </table>

        
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>News</heading>
            </td>
          </tr>
        </table>
        <ul>
          <li>
            <p>Two papers are accepted by ECCV 2022! (2022-07-04) <font color="ff0000"><strong><em>NEW!</em></strong></font></p>
          </li>
        </ul>
        <ul>
          <li>
            <p>One paper is accepted by MICCAI 2022! (2022-06-03)</p>
          </li>
        </ul> 
        <ul>
          <li>
            <p>Two papers are accepted by CVPR 2022! (2022-03-02)</p>
          </li>
        </ul>     
        <ul>
          <li>
            <p>One paper is accepted by MICCAI 2021! (2021-06-12)</p>
          </li>
        </ul>  
        <ul>
          <li>
            <p>One paper is accepted by CVPR 2020! (2020-02-24)</p>
          </li>
        </ul>
        <ul>
          <li>
            <p>One paper is accepted by ICCV 2019! (2019-07-23)</p>
          </li>
        </ul>
        <ul>
          <li>
            <p>One paper is accepted by AAAI 2019 as <strong>Oral</strong>! (2018-11-23)</p>
          </li>
        </ul>
              
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Education</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="cuhk.png" alt="cuhk" width="80" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>Aug. 2017 - Aug. 2021 </strong>, Department of Information Engineering,
                <i>
                  <b>the Chinese University of Hong Kong</b>
                </i></p>
              <p>Doctor of Philosophy</br>
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="nju.png" alt="nanjing" width="80" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>Sep. 2013 - Jul. 2017 </strong>, Department of Automation,
                <i>
                  <b>Nanjing University</b>
                </i></p>
              <p>Bachelor of Engineering</br>
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Industrial Experience</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="sensetime_logo.jpg" alt="sensetime" width="160" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>Apr. 2020 - May. 2020 </strong>,
                <i>
                  <b>internship in SenseTime</b> <p>Team leader: Dr.<a href="https://wang-zhe.me/"> Zhe Wang</a>
                </i></p>
              Research direction: knowledge distillation and network pruning in 3d detection</br>
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="sensetime_logo.jpg" alt="sensetime" width="160" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>Mar. 2017 - May. 2017 </strong>,
                <i>
                  <b>internship in SenseTime</b> <p>Team leader: Dr. <a href="https://scholar.google.com/citations?user=4m061tYAAAAJ&hl=en">Chunxiao Liu</a> and Dr. <a href="http://visal.cs.cityu.edu.hk/people/zheng-ma/">Zheng Ma</a>
                </i></p>
               Research direction: reinforcement learning in autonomous driving</br>
              </p>
            </td>
          </tr>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="PV-KD.PNG" alt="PV-KD" width="160" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Point-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation</papertitle>
                <br>
                <strong>Yuenan Hou</strong>, Xinge Zhu, Yuexin Ma, Chen Change Loy, Yikang Li
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022
                <br>
                <a href="https://arxiv.org/abs/2206.02099">[pdf]</a>
                <a href="https://github.com/cardwing/Codes-for-PVKD">[code]</a>
                <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/cardwing/Codes-for-PVKD?style=social"> 
                <img alt="GitHub forks" style="vertical-align:middle" src="https://img.shields.io/github/forks/cardwing/Codes-for-PVKD?style=social">
                <br>
                <p>
                  Rank <font color="ff0000">1st</font> on the Waymo 2022 3D Semantic Segmentation Challenge and SemanticKITTI LiDAR Semantic Segmentation Challenge (single-scan)!!!
                </p>
            </td>
          </tr>

        </table>


     <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="HMFI.PNG" alt="HMFI" width="160" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Homogeneous Multi-modal Feature Fusion and Interaction for 3D Object Detection</papertitle>
                <br>
                Xin Li, Botian Shi, <strong>Yuenan Hou</strong>, Xingjiao Wu, Tianlong Ma, Yikang Li, Liang He
                <br>
                <em>European Conference on Computer Vision</em>, 2022
                <br>
                <!–– <a href="https://openreview.net/forum?id=pbduKpYzn9j">[pdf]</a>
                <!–– <a href="https://github.com/cardwing/Codes-for-Lane-Detection">[code]</a>
                <br>
            </td>
          </tr> 

       </table>


     <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="StyleGAN-KD.PNG" alt="StyleGAN-KD" width="160" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Mind the Gap in Distilling StyleGANs</papertitle>
                <br>
                Guodong Xu, <strong>Yuenan Hou</strong>, Ziwei Liu, Chen Change Loy
                <br>
                <em>European Conference on Computer Vision</em>, 2022
                <br>
                <a href="https://arxiv.org/abs/2208.08840">[pdf]</a>
                <a href="https://github.com/xuguodong03/StyleKD">[code]</a>
                <br>
            </td>
          </tr> 

       </table>
       
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="ST-Crowd.PNG" alt="ST-Crowd" width="160" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>STCrowd: A Multimodal Dataset for Pedestrian Perception in Crowded Scenes</papertitle>
                <br>
                Peishan Cong, Xinge Zhu, Feng Qiao, Yiming Ren, Xidong Peng, <strong>Yuenan Hou</strong>, Lan Xu, Ruigang Yang, Dinesh Manocha, Yuexin Ma
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022
                <br>
                <a href="https://arxiv.org/abs/2204.01026">[pdf]</a>
                <a href="https://github.com/4DVLab/STCrowd">[code]</a>
                <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/4DVLab/STCrowd?style=social">
                <br>
            </td>
          </tr>

        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="DGKD.PNG" alt="DGKD" width="160" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Discrepancy and Gradient-guided Multi-modal Knowledge Distillation for Pathological Glioma Grading</papertitle>
                <br>
                Xiaohan Xing, Zhen Chen, Meilu Zhu, <strong>Yuenan Hou</strong>, Zhifan Gao, Yixuan Yuan
                <br>
                <em>International Conference on Medical Image Computing and Computer Assisted Intervension (MICCAI)</em>, 2022
                <br>
                [pdf]
                [code]
                <br>
            </td>
          </tr>

        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="CRCKD.PNG" alt="CRCKD" width="160" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Categorical Relation-Preserving Contrastive Knowledge Distillation for Medical Image Classification</papertitle>
                <br>
                Xiaohan Xing, <strong>Yuenan Hou</strong>, Hang Li, Yixuan Yuan, Hongsheng Li, Max Q.-H. Meng
                <br>
                <em>International Conference on Medical Image Computing and Computer Assisted Intervension (MICCAI)</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/2107.03225v1">[pdf]</a>
                <a href="https://github.com/hathawayxxh/CRCKD">[code]</a>
                <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/hathawayxxh/CRCKD?style=social">
                <br>
            </td>
          </tr>

        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="IntRA-KD.PNG" alt="IntRA-KD" width="160" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Inter-Region Affinity Distillation for Road Marking Segmentation</papertitle>
                <br>
                <strong>Yuenan Hou</strong>, Zheng Ma, Chunxiao Liu, Tak-Wai Hui, Chen Change Loy
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2020
                <br>
                <a href="https://arxiv.org/abs/2004.05304">[pdf]</a>
                <a href="https://github.com/cardwing/Codes-for-IntRA-KD">[code]</a>
                <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/cardwing/Codes-for-IntRA-KD?style=social">
                <img alt="GitHub forks" style="vertical-align:middle" src="https://img.shields.io/github/forks/cardwing/Codes-for-IntRA-KD?style=social">
                <br>
            </td>
          </tr>

        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="SAD.png" alt="SAD" width="160" height="120">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Learning Lightweight Lane Detection CNNs by Self Attention Distillation</papertitle>
                <br>
                <strong>Yuenan Hou</strong>, Zheng Ma, Chunxiao Liu, Chen Change Loy
                <br>
                <em>International Conference on Computer Vision (ICCV)</em>, 2019
                <br>
                <a href="https://arxiv.org/abs/1908.00821">[pdf]</a>
                <a href="https://github.com/cardwing/Codes-for-Lane-Detection">[code]</a>
                <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/cardwing/Codes-for-Lane-Detection?style=social">
                <img alt="GitHub forks" style="vertical-align:middle" src="https://img.shields.io/github/forks/cardwing/Codes-for-Lane-Detection?style=social">
                <br>
                <p>
                  One of the <font color="ff0000">most influential</font> paper in the lane detection field!
                </p>
            </td>
          </tr>

        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="/projects/FM-Net/intro.png" alt="FM-Net2018" width="160" height="120">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Learning to Steer by Mimicking Features from Heterogeneous Auxiliary Networks</papertitle>
                <br>
                <strong>Yuenan Hou</strong>, Zheng Ma, Chunxiao Liu, Chen Change Loy
                <br>
                <em>AAAI Conference on Artificial Intelligence (AAAI, <b>oral</b>)</em>, 2019
                <br>
                <a href="https://arxiv.org/abs/1811.02759">[pdf]</a>
                <a href="https://cardwing.github.io/projects/FM-Net">[project page]</a>
                <a href="https://github.com/cardwing/Codes-for-Steering-Control">[code]</a>
                <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/cardwing/Codes-for-Steering-Control?style=social">
                <img alt="GitHub forks" style="vertical-align:middle" src="https://img.shields.io/github/forks/cardwing/Codes-for-Steering-Control?style=social">
                <br>
            </td>
          </tr>

        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="per_ddpg.png" alt="per_ddpg" width="160" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>A Novel DDPG Method with Prioritized Experience Replay</papertitle>
                <br>
                <strong>Yuenan Hou</strong>, Lifeng Liu, Qing Wei, Xudong Xu, Chunlin Chen
                <br>
                <em>IEEE International Conference on Systems, Man, and Cybernetics (SMC)</em>, 2017
                <br>
                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8122622&tag=1">[pdf]</a>
                <a href="https://github.com/cardwing/Codes-for-RL-PER">[code]</a>
                <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/cardwing/Codes-for-RL-PER?style=social">
                <img alt="GitHub forks" style="vertical-align:middle" src="https://img.shields.io/github/forks/cardwing/Codes-for-RL-PER?style=social">
                <br>
            </td>
          </tr>

        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Preprint</heading>
            </td>
          </tr>
        </table>

     <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="taxonomy_bev.PNG" alt="BEV" width="160" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Vision-Centric BEV Perception: A Survey</papertitle>
                <br>
                Yuexin Ma, Tai Wang, Xuyang Bai, Huitong Yang, <strong>Yuenan Hou</strong>, Yaming Wang, Yu Qiao, Ruigang Yang, Dinesh Manocha, Xinge Zhu
                <br>
                <em>arXiv preprint arXiv:2208.02797</em>, 2022
                <br>
                <a href="https://arxiv.org/abs/2208.02797">[pdf]</a>
                <a href="https://github.com/4DVLab/Vision-Centric-BEV-Perception">[code]</a>
                <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/4DVLab/Vision-Centric-BEV-Perception?style=social">
                <img alt="GitHub forks" style="vertical-align:middle" src="https://img.shields.io/github/forks/4DVLab/Vision-Centric-BEV-Perception?style=social">
                <br>
            </td>
          </tr>       
       
          <tr>
            <td width="25%" align="center">
              <img src="ICPV.PNG" alt="ICPV" width="160" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>ICPV: Deep Fusion of Different Point Cloud Representations</papertitle>
                <br>
                Hao Tian, <strong>Yuenan Hou</strong>, Huijie Wang, Youquan Liu, Jiawei Li, Xinge Zhu, Wenkang Qin, Junchao Gong, Yang Li, Kai Li
                <br>
                <em><font color="ff0000">1st</font> Place Solution for 3D Semantic Segmentation Track in Waymo Open Dataset Challenge</em>, 2022
                <br>
                <a href="https://storage.googleapis.com/waymo-uploads/files/research/3DSemSeg/3DSemseg_Cylinder3D.pdf">[pdf]</a>
                <a href="https://github.com/cardwing/Codes-for-PVKD">[code]</a>
                <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/cardwing/Codes-for-PVKD?style=social">
                <img alt="GitHub forks" style="vertical-align:middle" src="https://img.shields.io/github/forks/cardwing/Codes-for-PVKD?style=social">
                <br>
            </td>
          </tr>
       
          <tr>
            <td width="25%" align="center">
              <img src="PEEL.PNG" alt="PEEL" width="160" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Network Pruning via Resource Reallocation</papertitle>
                <br>
                <strong>Yuenan Hou</strong>, Zheng Ma, Chunxiao Liu, Zhe Wang, Chen Change Loy
                <br>
                <em>arXiv preprint arXiv:2103.01847</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/2103.01847">[pdf]</a>
                <!–– <a href="https://github.com/cardwing/Codes-for-Lane-Detection">[code]</a>
                <!–– <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/cardwing/Codes-for-Lane-Detection?style=social">
                <!–– <img alt="GitHub forks" style="vertical-align:middle" src="https://img.shields.io/github/forks/cardwing/Codes-for-Lane-Detection?style=social">
                <br>
            </td>
          </tr>

          <tr>
            <td width="25%" align="center">
              <img src="ENet_label.png" alt="ENet_label" width="160" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Agnostic Lane Detection</papertitle>
                <br>
                <strong>Yuenan Hou</strong>
                <br>
                <em>arXiv preprint arXiv:1905.03704</em>, 2019
                <br>
                <a href="https://www.researchgate.net/publication/332528412_Agnostic_Lane_Detection">[pdf]</a>
                <a href="https://github.com/cardwing/Codes-for-Lane-Detection">[code]</a>
                <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/cardwing/Codes-for-Lane-Detection?style=social">
                <img alt="GitHub forks" style="vertical-align:middle" src="https://img.shields.io/github/forks/cardwing/Codes-for-Lane-Detection?style=social">
                <br>
            </td>
          </tr>

        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Selected Course Work</heading>
            </td>
          </tr>
        </table>
        <ul>
          <li>
            <p><a href="https://cardwing.github.io/files/RL_course_report.pdf">Improving DDPG via Prioritized Experience Replay</a>, <a href="https://course.ie.cuhk.edu.hk/~ierg6130/index.html">IERG 6130 Reinforcement Learning</a></p>
          </li>
        </ul>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Academic Services</heading>
            </td>
          </tr>
        </table>
        <ul>
          <li>
            <p>Conference reviewer of CVPR, ICCV, ECCV, AAAI, IJCAI</p>
          </li>
        </ul>
        <ul>
          <li>
            <p>Journal reviewer of TPAMI, IJCV, TIP, Neurocomputing, RA-L, IET, TGRS, JSTARS</p>
          </li>
        </ul>
        <ul>
          <li>
            <p>Invited talk at School of Information Science and Technology, ShanghaiTech University, "Recent Advances and Challenges of 3D Perception Tasks", 2022</p>
          </li>
        </ul>
        <ul>
          <li>
            <p>Invited talk at School of Computer Science, Wuhan University, "Improving Deep Network Performance via Model Compression", 2021 <a href="https://cardwing.github.io/files/Improving_Deep_Network_Performance_via_Model_Compression.pdf">[ppt pdf]</a></p>
          </li>
        </ul>
        <ul>
          <li>
            <p>Invited talk at School of Cyber Science and Engineering, Wuhan University, "Improving Deep Network Performance via Model Compression", 2021</p>
          </li>
        </ul>
        <ul>
          <li>
            <p>Invited talk at School of Artificial Intelligence, Sun Yat-sen University, "Improving Deep Network Performance via Model Compression", 2020</p>
          </li>
        </ul>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Honors and Awards</heading>
            </td>
          </tr>
        </table>
        <ul>
          <li>
            <p>Rank 1st in SemanticKITTI Semantic Scene Completion Challenge, 1/19, the "pjxyz" entity, Jul. 2022</p>
          </li>    
          <li>
            <p>Rank 1st in SemanticKITTI Panoptic Segmentation Challenge, 1/30, the "quanyyds" entity, Jul. 2022</p>
          </li> 
          <li>
            <p>Rank 1st in SemanticKITTI 4D Panoptic Segmentation Challenge, 1/7, the "quanyyds" entity, Jul. 2022</p>
          </li> 
          <li>
            <p>Rank 1st in SemanticKITTI LiDAR Semantic Segmentation Challenge (single-scan), 1/300, the "Point-Voxel-KD" entity, Jun. 2022</p>
          </li>
          <li>
            <p>Rank 1st in Waymo 3D Semantic Segmentation Challenge, 1/20, the "Cylinder3D" entity, May 2022</p>
          </li> 
          <li>
            <p>Shanghai Leading Talent Program, Shanghai Government, Dec. 2021</p>
          </li>
          <li>
            <p>Shanghai Specially-Invited Expert, Shanghai Government, Dec. 2021</p>
          </li>  
          <li>
            <p>Rank 2nd in SemanticKITTI LiDAR Semantic Segmentation Challenge (multi-scan), 2/100, the "PVKD" entity, Dec. 2021</p>
          </li>    
          <li>
            <p>Rank 1st in ApolloScape Lane Segmentation Challenge, Baidu, 1/104, the "Codes-for-IntRA-KD" entity, Sep. 2020</p>
          </li>       
          <li>
            <p>Postgraduate Scholarship, the Chinese University of Hong Kong, 2017 ~ 2021</p>
          </li>
          <li>
            <p>Third Prize of Jiangsu Province for Undergraduate Thesis, Nanjing University, 2017 <a href="https://cardwing.github.io/files/131270027-侯跃南-陈春林.pdf">[paper pdf]</a> <a href="http://jyt.jiangsu.gov.cn/module/download/downfile.jsp?classid=0&filename=0b7f135a90de478b92b389b3b54c7312.pdf">[awards list]</a></p>
          </li>
          <li>
            <p>Zhenggang Scholarship, Nanjing University, 2017</p>
          </li>
          <li>
            <p>Mathematical Contest in Modeling (MCM), Meritorious Winner (13%), 2016 <a href="https://cardwing.github.io/files/49652.pdf">[paper pdf]</a></p>
          </li>   
          <li>
            <p>Liao's Scholarship, Nanjing University, 2015</p>
          </li>
          <li>
            <p>National Scholarship, Nanjing University, 2014</p>
          </li>
        </ul>
        <br />
        <!-- Footer ================================================== -->
        <hr>

        <footer class="footer">
          <div class="container">
            <p>
              &nbsp;&nbsp;&nbsp;Updated Aug 2022</p>
            </p>
            <p align=right>
              <a href="https://ai.stanford.edu/~kaidicao/"> Page Template </a>
              <a class="pull-right" href="#">
                <center><a href="https://clustrmaps.com/site/1af29"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=N4fuA3R36CqTde01_juk6Hi7ossGUo6W7m_PXVkPHGg&cl=ffffff" /></a></center>
              </a>
            </p>
          </div>
        </footer>

        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost +
            "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
      </td>
    </tr>
  </table>
</body>

</html>
